{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final-proposed-model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iamuRgeiNLjW",
        "colab_type": "text"
      },
      "source": [
        "## GPU Init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZG4BqkENEyd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4346cd2c-d083-49a1-d821-1001d28fb782"
      },
      "source": [
        "# Taken from\n",
        "# https://stackoverflow.com/questions/48750199/google-colaboratory-misleading-information-about-its-gpu-only-5-ram-available\n",
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# Colab only provides one GPU and it is not always guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python2.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python2.7/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBvIvBoyg68g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "eaffc22a-98df-435f-c499-1c1fad210c9b"
      },
      "source": [
        "printm()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('RAM Free: 12.8 GB', ' | Proc size: 91.7 MB')\n",
            "GPU RAM Free: 15079MB | Used: 0MB | Util   0% | Total 15079MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMiynJ7p-zI8",
        "colab_type": "text"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV1m-9ZGuKGj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f8de098-5f1c-49cd-b8a6-e2d02f8965fa"
      },
      "source": [
        "# Clone repo\n",
        "!git clone https://github.com/MatchLab-Imperial/keras_triplet_descriptor"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'keras_triplet_descriptor' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyZSqhZ5LACT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e5d45da-32f9-4041-8da8-2fbc5f9bfcf6"
      },
      "source": [
        "# Change directory\n",
        "%cd /content/keras_triplet_descriptor    \n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/keras_triplet_descriptor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "307CBCL-FjX4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "498d7a75-3e1e-4820-d27b-b4ca90d2e179"
      },
      "source": [
        "# Download data\n",
        "!wget -O hpatches_data.zip https://imperialcollegelondon.box.com/shared/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-19 06:45:20--  https://imperialcollegelondon.box.com/shared/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Resolving imperialcollegelondon.box.com (imperialcollegelondon.box.com)... 185.235.236.197\n",
            "Connecting to imperialcollegelondon.box.com (imperialcollegelondon.box.com)|185.235.236.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip [following]\n",
            "--2020-08-19 06:45:21--  https://imperialcollegelondon.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Reusing existing connection to imperialcollegelondon.box.com:443.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://imperialcollegelondon.app.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip [following]\n",
            "--2020-08-19 06:45:21--  https://imperialcollegelondon.app.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Resolving imperialcollegelondon.app.box.com (imperialcollegelondon.app.box.com)... 185.235.236.201\n",
            "Connecting to imperialcollegelondon.app.box.com (imperialcollegelondon.app.box.com)|185.235.236.201|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://public.boxcloud.com/d/1/b1!KmUgEcOYXfIWyRYC_tnnFaSbtYHWNZYAR-0_dSwXmn7hJEjqxA_h2M4wRiyAiJg9dzv2LHjtaPoN62Mo36T_iEJ_k8RRmqWkHoCVO9aWXks4lAIqwmf5AFeTzqax1Q45EFNRxfZTOR8tUJfTOc-ZJ1Pj_Eq0FhQ8JB-tjGKGMhdH8BskZQZALoVrgRD6ZrSfh2jFEGs5QzLuKKfsIvC7NwW7yffApXjfV7-7YCxTovpe9_TlhQjuuxNW-wqOetKt-HOXel7VF3m1nhAYFlyjcaLgreirRcGeReh9NhuSLFO-tNx_IBLP5ar42ju5-bLqiflUcmFg3Q4lUOzjSCUKhcWRmEZ6fV_SJKTvGWlxxgFtHmLnvi8Ys_2pDzLvcVfGhx2NeaiielTLgQkyMIDASZDRgW0YNyW6TKvc2RV0mLixApCjDOiiOIk9fTZwPO6WYiujuQ2Cr_CsuTiQDe05gdW2xKlbE1l8pNvgtldIoXcAF9xyCDfefH43lheMcMGwJ4N_m_S9aZsiLomttvgOkVibLVJXj5tTTESnCUzCs5sr40d68Q0bTCeEIDWSTY2lK4EDSOw8F_5_NCS0kVYnvMyKtQcXt5OobYR8Ty6RALk5-UcoTBB3K6GrsTspX9rEHlaAnsLz81q_E-PjGJ3siMgzkxb83qU4L568hV0VqNCgrYnPbrXcSPAMLWsZwYRVDt-xqGWq4jvuk4L7RHAK5tPTS4E6WciLGmKJz5LLEFXqB_GAh3-mQBzEqNIgQ39zh7awwa2BUY0Vz3BZzj-uqvNkn-rsGgeglzC61emPHO8zV57YyITlqIcLpLgqjlQaHKk1Of7Y03SUbcZvzTvsvVK8KBtQFnlcjZqrWROEXkUIU35KZxNJMUAcG1m2tOxCVUMVwEK8Lgh3GDHd9R4feX011ReP-cUnzXNn8gv1Zaia7p0EwbY0zutFnHPXpoUyCgnk3AD7wJ9iAsmlxQWXOAcFMLqL7RwgmEIrhVPGf5NF5Bbueq5QPCKyHiAeV8KuiGgUt1SQrp5tJqjJz0X_vASDeifAc_nXJTvQoCmYF1-sGPJhl2i__m1tI5gAuUCeJqAve4_9_lHjtJOXNb6Dr6vKaiZm6aaZUqTp3j6gkld4K8YjORW6oCJei1iQvhHAS2llmK2n6Sa85q2AsE-R_1Lc8Sy597yjzlMIb9QdwCf18tnD9rhCNHtrfhJUQE-zRMPFpnIrt6JzCWMxxsR6Fnld7m4iB94DwaRedVLKv5wt9ohM5s3VV-FCX5LinjNm0nEzsmX1J2Hc3BZF-NZiqLSgRoK3E1brPEbkExKu2qEqoqtuwvr1pBmo5v50cWARojoFYGKHomkjhs2rJp1R7w4CNobsG0h9Qw6eXfAvhPNBNnNpUURp5elE1U_ujAxioA6cDZxLj7hRzZJGkXy66awnhz_R7AG8O8SaOnc3ggUZiCz61JTYKKUBg00b9yo./download [following]\n",
            "--2020-08-19 06:45:21--  https://public.boxcloud.com/d/1/b1!KmUgEcOYXfIWyRYC_tnnFaSbtYHWNZYAR-0_dSwXmn7hJEjqxA_h2M4wRiyAiJg9dzv2LHjtaPoN62Mo36T_iEJ_k8RRmqWkHoCVO9aWXks4lAIqwmf5AFeTzqax1Q45EFNRxfZTOR8tUJfTOc-ZJ1Pj_Eq0FhQ8JB-tjGKGMhdH8BskZQZALoVrgRD6ZrSfh2jFEGs5QzLuKKfsIvC7NwW7yffApXjfV7-7YCxTovpe9_TlhQjuuxNW-wqOetKt-HOXel7VF3m1nhAYFlyjcaLgreirRcGeReh9NhuSLFO-tNx_IBLP5ar42ju5-bLqiflUcmFg3Q4lUOzjSCUKhcWRmEZ6fV_SJKTvGWlxxgFtHmLnvi8Ys_2pDzLvcVfGhx2NeaiielTLgQkyMIDASZDRgW0YNyW6TKvc2RV0mLixApCjDOiiOIk9fTZwPO6WYiujuQ2Cr_CsuTiQDe05gdW2xKlbE1l8pNvgtldIoXcAF9xyCDfefH43lheMcMGwJ4N_m_S9aZsiLomttvgOkVibLVJXj5tTTESnCUzCs5sr40d68Q0bTCeEIDWSTY2lK4EDSOw8F_5_NCS0kVYnvMyKtQcXt5OobYR8Ty6RALk5-UcoTBB3K6GrsTspX9rEHlaAnsLz81q_E-PjGJ3siMgzkxb83qU4L568hV0VqNCgrYnPbrXcSPAMLWsZwYRVDt-xqGWq4jvuk4L7RHAK5tPTS4E6WciLGmKJz5LLEFXqB_GAh3-mQBzEqNIgQ39zh7awwa2BUY0Vz3BZzj-uqvNkn-rsGgeglzC61emPHO8zV57YyITlqIcLpLgqjlQaHKk1Of7Y03SUbcZvzTvsvVK8KBtQFnlcjZqrWROEXkUIU35KZxNJMUAcG1m2tOxCVUMVwEK8Lgh3GDHd9R4feX011ReP-cUnzXNn8gv1Zaia7p0EwbY0zutFnHPXpoUyCgnk3AD7wJ9iAsmlxQWXOAcFMLqL7RwgmEIrhVPGf5NF5Bbueq5QPCKyHiAeV8KuiGgUt1SQrp5tJqjJz0X_vASDeifAc_nXJTvQoCmYF1-sGPJhl2i__m1tI5gAuUCeJqAve4_9_lHjtJOXNb6Dr6vKaiZm6aaZUqTp3j6gkld4K8YjORW6oCJei1iQvhHAS2llmK2n6Sa85q2AsE-R_1Lc8Sy597yjzlMIb9QdwCf18tnD9rhCNHtrfhJUQE-zRMPFpnIrt6JzCWMxxsR6Fnld7m4iB94DwaRedVLKv5wt9ohM5s3VV-FCX5LinjNm0nEzsmX1J2Hc3BZF-NZiqLSgRoK3E1brPEbkExKu2qEqoqtuwvr1pBmo5v50cWARojoFYGKHomkjhs2rJp1R7w4CNobsG0h9Qw6eXfAvhPNBNnNpUURp5elE1U_ujAxioA6cDZxLj7hRzZJGkXy66awnhz_R7AG8O8SaOnc3ggUZiCz61JTYKKUBg00b9yo./download\n",
            "Resolving public.boxcloud.com (public.boxcloud.com)... 185.235.236.200\n",
            "Connecting to public.boxcloud.com (public.boxcloud.com)|185.235.236.200|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4088106554 (3.8G) [application/zip]\n",
            "Saving to: ‘hpatches_data.zip’\n",
            "\n",
            "hpatches_data.zip   100%[===================>]   3.81G  12.2MB/s    in 5m 27s  \n",
            "\n",
            "2020-08-19 06:50:49 (11.9 MB/s) - ‘hpatches_data.zip’ saved [4088106554/4088106554]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36mBTFvPCxY9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "911df5cc-c7a1-4998-a879-425fa4edca70"
      },
      "source": [
        "# Extract data\n",
        "!unzip -q ./hpatches_data.zip\n",
        "!rm ./hpatches_data.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replace hpatches/v_man/e3.anisjitter? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0KYfe-at9KN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0f71691-81f8-4c3d-ef32-90a484e466cb"
      },
      "source": [
        "import sys\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda, Reshape\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization \n",
        "from keras.layers import Input, UpSampling2D, concatenate  \n",
        "\n",
        "from read_data import HPatches, DataGeneratorDesc, hpatches_sequence_folder, DenoiseHPatches, tps\n",
        "from utils import generate_desc_csv, plot_denoise, plot_triplet"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enFLJLfoxnU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_history(history, metric = None):\n",
        "  # Plots the loss history of training and validation (if existing)\n",
        "  # and a given metric\n",
        "  \n",
        "  if metric != None:\n",
        "    fig, axes = plt.subplots(2,1)\n",
        "    axes[0].plot(history.history[metric])\n",
        "    try:\n",
        "      axes[0].plot(history.history['val_'+metric])\n",
        "      axes[0].legend(['Train', 'Val'])\n",
        "    except:\n",
        "      pass\n",
        "    axes[0].set_title('{:s}'.format(metric))\n",
        "    axes[0].set_ylabel('{:s}'.format(metric))\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    fig.subplots_adjust(hspace=0.5)\n",
        "    axes[1].plot(history.history['loss'])\n",
        "    try:\n",
        "      axes[1].plot(history.history['val_loss'])\n",
        "      axes[1].legend(['Train', 'Val'])\n",
        "    except:\n",
        "      pass\n",
        "    axes[1].set_title('Model Loss')\n",
        "    axes[1].set_ylabel('Loss')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "  else:\n",
        "    plt.plot(history.history['loss'])\n",
        "    try:\n",
        "      plt.plot(history.history['val_loss'])\n",
        "      plt.legend(['Train', 'Val'])\n",
        "    except:\n",
        "      pass\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXL31ez-AT5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random.seed(1234)\n",
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABKDHB9RApZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hpatches_dir = './hpatches'\n",
        "splits_path = './splits.json'\n",
        "\n",
        "splits_json = json.load(open(splits_path, 'rb'))\n",
        "split = splits_json['a']\n",
        "\n",
        "train_fnames = split['train']\n",
        "test_fnames = split['test']\n",
        "\n",
        "seqs = glob.glob(hpatches_dir+'/*')\n",
        "seqs = [os.path.abspath(p) for p in seqs]   \n",
        "seqs_train = list(filter(lambda x: x.split('/')[-1] in train_fnames, seqs)) \n",
        "seqs_test = list(filter(lambda x: x.split('/')[-1] in split['test'], seqs)) \n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeWik0vMEtuC",
        "colab_type": "text"
      },
      "source": [
        "## Final UNet/L2Net architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6QbkHnbuIUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def final_UNet(shape):\n",
        "  \"\"\"\n",
        "  Returns the denoising model. \n",
        "  The input for the function is the size of the patch, which will be *1x32x32*, \n",
        "  and it outputs a keras denoising model.\n",
        "\n",
        "  \"\"\"\n",
        "    \n",
        "  inputs = Input(shape)\n",
        "  \n",
        "  ## Encoder\n",
        "  conv1 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'lecun_uniform')(inputs)\n",
        "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "  \n",
        "  ## Bottleneck\n",
        "  conv2 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'lecun_uniform')(pool1)\n",
        "  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)  \n",
        "  \n",
        "  conv3 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'lecun_uniform')(pool2)\n",
        "  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "  \n",
        "  ## Decoder\n",
        "  conv4 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'lecun_uniform')(pool3)\n",
        "  \n",
        "  up5 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'lecun_uniform')(UpSampling2D(size = (2,2))(conv4))\n",
        "  merge5 = concatenate([conv3,up5], axis = -1)\n",
        "  conv5 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'lecun_uniform')(merge5)\n",
        "\n",
        "  up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'lecun_uniform')(UpSampling2D(size = (2,2))(conv5))\n",
        "  merge6 = concatenate([conv2,up6], axis = -1)\n",
        "  conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'lecun_uniform')(merge6)\n",
        "    \n",
        "  up7 = Conv2D(1024, 2, activation = 'relu', padding = 'same', kernel_initializer = 'lecun_uniform')(UpSampling2D(size = (2,2))(conv6))\n",
        "  merge7 = concatenate([conv1,up7], axis = -1)\n",
        "  conv7 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'lecun_uniform')(merge7)\n",
        "\n",
        "  conv8 = Conv2D(1,3,padding='same')(conv7)\n",
        "\n",
        "  shallow_net = Model(inputs = inputs, outputs = conv8)\n",
        "  \n",
        "  return shallow_net\n",
        "\n",
        "def final_L2Net(shape):\n",
        "  \n",
        "  '''\n",
        "  Builds the descriptor model. The input for the function is the size of the patch, \n",
        "  which will be *1x32x32*, and it outputs a keras descriptor model. The model we use as \n",
        "  baseline returns a descriptor of dimension *128x1*.\n",
        "  \n",
        "  '''\n",
        "  \n",
        "  init_weights = keras.initializers.glorot_normal()\n",
        "  \n",
        "  descriptor_model = Sequential()\n",
        "  descriptor_model.add(Conv2D(32, 3, padding='same', input_shape=shape, use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(32, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(64, 3, padding='same', strides=2, use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(64, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 3, padding='same', strides=2,  use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "  descriptor_model.add(Dropout(0.3))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 8, padding='valid', use_bias = True, kernel_initializer=init_weights))\n",
        "  \n",
        "  # Final descriptor reshape\n",
        "  descriptor_model.add(Reshape((128,)))\n",
        "  \n",
        "  return descriptor_model\n",
        "  \n",
        "  \n",
        "def triplet_loss(x):\n",
        "  \"\"\"\n",
        "  Defines the loss function which is used to train the descriptor model.\n",
        "\n",
        "  \"\"\"\n",
        "  \n",
        "  output_dim = 128\n",
        "  a, p, n = x\n",
        "  _alpha = 1.0\n",
        "  positive_distance = K.mean(K.square(a - p), axis=-1)\n",
        "  negative_distance = K.mean(K.square(a - n), axis=-1)\n",
        "  \n",
        "  return K.expand_dims(K.maximum(0.0, positive_distance - negative_distance + _alpha), axis = 1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlS5zcV7EJgp",
        "colab_type": "text"
      },
      "source": [
        "## Denoising Image Patches\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHxHwjUd3-pY",
        "colab_type": "text"
      },
      "source": [
        "We use the *DenoiseHPatches* class implemented in the read_data.py file, which takes as input the list of sequences to load and the size of batches. \n",
        "\n",
        "*DenoiseHPatches* outputs batches where the input data is the noisy image and the label is the clean image, so we can use a mean absolute error (MAE) metric as loss function. \n",
        "\n",
        "Afterward, a subset of training and validation sequences by using *random.sample* (3 sequences for training and 1 for validation data). Remove the random.sample function to give the generator all the training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_VPSHmSK0dS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "071a0bb0-8b72-429a-d676-57b6e9972907"
      },
      "source": [
        "denoise_generator = DenoiseHPatches(random.sample(seqs_train, 3), batch_size=32)\n",
        "denoise_generator_val = DenoiseHPatches(random.sample(seqs_test, 1), batch_size=32)\n",
        "\n",
        "# Uncomment following lines for using all the data to train the denoising model\n",
        "# denoise_generator = DenoiseHPatches(seqs_train, batch_size=32)\n",
        "# denoise_generator_val = DenoiseHPatches(seqs_test, batch_size=32)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:03<00:00,  1.18s/it]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.79it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eUSba93Dttj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shape = (32, 32, 1)\n",
        "denoise_model = final_UNet(shape)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edwbgE6yKqcD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4f3f5a04-5c00-4ae1-ba93-7ef040ee5795"
      },
      "source": [
        "nadam = keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, schedule_decay=0.004)\n",
        "denoise_model.compile(loss='mean_absolute_error', optimizer=nadam, metrics=['accuracy'])\n",
        "epochs = 1\n",
        "### Use a loop to save for each epoch the weights in an external website in\n",
        "### case colab stops. Every time you call fit/fit_generator the weigths are NOT\n",
        "### reset, so e.g. calling 5 times fit(epochs=1) behave as fit(epochs=5)\n",
        "for e in range(epochs):\n",
        "  denoise_history = denoise_model.fit_generator(generator=denoise_generator, \n",
        "                                                epochs=50, verbose=1, \n",
        "                                                validation_data=denoise_generator_val)\n",
        "  # denoise_model.save('denoise.h5') \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "   4/2370 [..............................] - ETA: 1:23:34 - loss: 519849.2561 - accuracy: 0.0030    "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjAQRnPV47BI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot learning curves\n",
        "plot_history(denoise_history)\n",
        "plot_history(denoise_history,'val_acc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFA_8uN4Eb3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualization of denoised images\n",
        "plot_denoise(denoise_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyABaCvkEPDR",
        "colab_type": "text"
      },
      "source": [
        "## Training a Descriptor Network\n",
        "In the last section we trained a model that given a noisy patch, outputs a denoised version of it. We hoped that by doing so, we will improve the performance of the second part, which is training a network that outputs the descriptor. As we mentioned, a descriptor is a numerical vector that represents the small images we have. The dataset consists of a large number of small images, which are cropped patches from other larger images. Hence, they represent some local part of a scene. That is why there are no objects represented, only corners or textures. Each of these patches is related to a subset of other patches of the dataset by some kind of geometric transformation (e.g. rotation).  For a given patch, we want the network to output a vector that is close to the vectors of the patches that represent the same local part of a scene, while being far from patches do not represent that local part of a scene.\n",
        "\n",
        "To do so, we will build a convolutional neural network that takes the input of $32\\times32$ and outputs a descriptor of size $128$. For the loss, we use the triplet loss, which takes an anchor patch, a negative patch and a positive patch. The idea is to train the network so the descriptors from the anchor and positive patch have a low distance between them, and the negative and anchor patch have a large distance between them. \n",
        "\n",
        "In this cell we generate a triplet network, which is a network formed by three copies of the same network. That means that the descriptor model will compute the descriptor for the input `'a'` (anchor), the same descriptor model (with the same weights) will compute the descriptor for the input `'p'` (positive), and again the same model will compute the descriptor for the input `'n'` (negative). \n",
        "\n",
        "**Updated explanation**: Due to the way Keras handles the compile method, it needs a loss as an argument in that compile method. However, our loss is computed in the lambda layer, so we want to minimize the output of that layer. As we want to minimize the output of the Lambda function (in this case the triplet loss), we output as the label in the training_generator a vector of zeros and we compute the mean absolute error of the triplet loss and this vector of zeros. What we aim to minimize is therefore:\n",
        "$$  |\\text{triplet_loss} - 0| =  |\\text{triplet_loss}| = \\text{triplet_loss} $$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVmDZIRTHPDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Lambda\n",
        "shape = (32, 32, 1)\n",
        "xa = Input(shape=shape, name='a')\n",
        "xp = Input(shape=shape, name='p')\n",
        "xn = Input(shape=shape, name='n')\n",
        "descriptor_model = final_L2Net(shape)\n",
        "ea = descriptor_model(xa)\n",
        "ep = descriptor_model(xp)\n",
        "en = descriptor_model(xn)\n",
        "\n",
        "loss = Lambda(triplet_loss)([ea, ep, en])\n",
        "\n",
        "descriptor_model_trip = Model(inputs=[xa, xp, xn], outputs=loss)\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
        "descriptor_model_trip.compile(loss='mean_absolute_error', optimizer=adamax, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIR1cH4fDwKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Descriptor loading and training\n",
        "# Loading images\n",
        "hPatches = HPatches(train_fnames=train_fnames, test_fnames=test_fnames,\n",
        "                    denoise_model=denoise_model, use_clean=False)\n",
        "# Creating training generator\n",
        "training_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=1), num_triplets=1000000)\n",
        "# Creating validation generator\n",
        "val_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=0), num_triplets=100000)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RQmOMU92csu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_triplet(training_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPyc8as42WTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train Descriptor L2Net\n",
        "\n",
        "epochs = 1\n",
        "### As with the denoising model, we use a loop to save for each epoch \n",
        "## #the weights in an external website in case colab stops. \n",
        "### reset, so e.g. calling 5 times fit(epochs=1) behave as fit(epochs=5)\n",
        "\n",
        "### If you have a model saved from a previous training session\n",
        "### Load it in the next line\n",
        "# descriptor_model_trip.set_weights(keras.models.load_model('./descriptor.h5').get_weights())\n",
        "# descriptor_model_trip.optimizer = keras.models.load_model('./descriptor.h5').optimizer\n",
        "\n",
        "for e in range(epochs):\n",
        "  \n",
        "  descriptor_history = descriptor_model_trip.fit_generator(generator=training_generator, epochs=50, verbose=1, validation_data=val_generator)\n",
        "  \n",
        "  #descriptor_model_trip.save('descriptor.h5') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrC24wbmAhQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot Learning Curves\n",
        "plot_history(descriptor_history)\n",
        "plot_history(descriptor_history,'val_acc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DysQEXFBUtwi",
        "colab_type": "text"
      },
      "source": [
        "# Descriptor Evaluation\n",
        "To evaluate the performance of the final model, we will use the HPatches benchmark. HPatches benchmark takes as input the descriptors for the test data in a CSV form. \n",
        "\n",
        "This function generates those files by passing it a descriptor model and a denoising model. It performs a first step of denoising the patches, and a second one of computing the descriptor of the denoised patch. If no denoising model is given (variable set to `None`), the descriptor is computed directly in the noisy patch.\n",
        "\n",
        "Similarly to the loading data part, you have the denoise_model variable and `use_clean` variable. If `use_clean` is set to True, the CSV generated will be those of the clean patches, even if a denoising model is given. If set to False, then depends on the variable `denoise_model`. If there is no denoise model (`denoise_model=None`), then it will use the noisy patches. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiJb2XDG9bsJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " generate_desc_csv(descriptor_model, seqs_test, denoise_model=denoise_model, use_clean=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvOGRh3sc9Wo",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Now we will perform the evaluation of three different tasks (Verification, Matching and Evaluation) using the descriptor CSV files. The definition of the three different tasks is taken from the [HPatches paper](https://arxiv.org/pdf/1704.05939.pdf).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Awnyv4xTYSFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Verification: \n",
        "# Patch verification measures the ability of a descriptor to classify whether two patches are extracted \n",
        "# from the same measurement.\n",
        "\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=verification --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=verification\n",
        "\n",
        "# Matching:\n",
        "# Image matching, tests to what extent a descriptor can correctly identify correspondences in two images.\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=matching --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=matching\n",
        "\n",
        "# Retrieval\n",
        "# Retrieval tests how well a descriptor can match a query patch to a pool of patches extracted from many images.\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=retrieval --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=retrieval\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgZcAymodKkq",
        "colab_type": "text"
      },
      "source": [
        "# 5 UNet epochs with all patches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UpmFkTra05r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "denoise_generator = DenoiseHPatches(seqs_train, batch_size=32)\n",
        "denoise_generator_val = DenoiseHPatches(seqs_test, batch_size=32)\n",
        "\n",
        "shape = (32, 32, 1)\n",
        "denoise_model = final_UNet(shape)\n",
        "\n",
        "nadam = keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, schedule_decay=0.004)\n",
        "denoise_model.compile(loss='mean_absolute_error', optimizer=nadam, metrics=['accuracy'])\n",
        "epochs = 1\n",
        "### Use a loop to save for each epoch the weights in an external website in\n",
        "### case colab stops. Every time you call fit/fit_generator the weigths are NOT\n",
        "### reset, so e.g. calling 5 times fit(epochs=1) behave as fit(epochs=5)\n",
        "for e in range(epochs):\n",
        "  denoise_history = denoise_model.fit_generator(generator=denoise_generator, \n",
        "                                                epochs=5, verbose=1, \n",
        "                                                validation_data=denoise_generator_val)\n",
        "  # denoise_model.save('denoise.h5') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qv3oH9Cc1fw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot learning curves\n",
        "plot_history(denoise_history)\n",
        "plot_history(denoise_history,'val_acc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b18XxT3ac2B-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Lambda\n",
        "shape = (32, 32, 1)\n",
        "xa = Input(shape=shape, name='a')\n",
        "xp = Input(shape=shape, name='p')\n",
        "xn = Input(shape=shape, name='n')\n",
        "descriptor_model = final_L2Net(shape)\n",
        "ea = descriptor_model(xa)\n",
        "ep = descriptor_model(xp)\n",
        "en = descriptor_model(xn)\n",
        "\n",
        "loss = Lambda(triplet_loss)([ea, ep, en])\n",
        "\n",
        "descriptor_model_trip = Model(inputs=[xa, xp, xn], outputs=loss)\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
        "descriptor_model_trip.compile(loss='mean_absolute_error', optimizer=adamax, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uzeUo2qc8wA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Descriptor loading and training\n",
        "# Loading images\n",
        "hPatches = HPatches(train_fnames=train_fnames, test_fnames=test_fnames,\n",
        "                    denoise_model=denoise_model, use_clean=False)\n",
        "# Creating training generator\n",
        "training_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=1), num_triplets=1000000)\n",
        "# Creating validation generator\n",
        "val_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=0), num_triplets=100000)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suIT8tdVc-r6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_triplet(training_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuvcAXJNc_Gb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train Descriptor L2Net\n",
        "\n",
        "epochs = 1\n",
        "### As with the denoising model, we use a loop to save for each epoch \n",
        "## #the weights in an external website in case colab stops. \n",
        "### reset, so e.g. calling 5 times fit(epochs=1) behave as fit(epochs=5)\n",
        "\n",
        "### If you have a model saved from a previous training session\n",
        "### Load it in the next line\n",
        "# descriptor_model_trip.set_weights(keras.models.load_model('./descriptor.h5').get_weights())\n",
        "# descriptor_model_trip.optimizer = keras.models.load_model('./descriptor.h5').optimizer\n",
        "\n",
        "for e in range(epochs):\n",
        "  \n",
        "  descriptor_history = descriptor_model_trip.fit_generator(generator=training_generator, epochs=50, verbose=1, validation_data=val_generator)\n",
        "  \n",
        "  #descriptor_model_trip.save('descriptor.h5') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7Qt9XrgdBWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot Learning Curves\n",
        "plot_history(descriptor_history)\n",
        "plot_history(descriptor_history,'val_acc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afByVmE4dDSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " generate_desc_csv(descriptor_model, seqs_test, denoise_model=denoise_model, use_clean=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_htoJtNNdFjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Verification: \n",
        "# Patch verification measures the ability of a descriptor to classify whether two patches are extracted \n",
        "# from the same measurement.\n",
        "\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=verification --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=verification\n",
        "\n",
        "# Matching:\n",
        "# Image matching, tests to what extent a descriptor can correctly identify correspondences in two images.\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=matching --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=matching\n",
        "\n",
        "# Retrieval\n",
        "# Retrieval tests how well a descriptor can match a query patch to a pool of patches extracted from many images.\n",
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=retrieval --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=retrieval\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bn6lBLR1ddrC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}